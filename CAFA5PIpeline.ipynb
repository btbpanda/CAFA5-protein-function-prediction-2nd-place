{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "\n",
    "Running this notebook end-to-end will reproduce the solution. Step by step guide is also provided. You can skip some long running steps by executing corresponding cells of `Download.ipynb` to download artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_path: ./ # working dir\r\n",
      "# environments\r\n",
      "rapids-env: rapids-env/bin/python\r\n",
      "pytorch-env: pytorch-env/bin/python\r\n",
      "# artifacts paths\r\n",
      "embeds_path: embeds # path to embeddings \r\n",
      "models_path: models # store the models\r\n",
      "helpers_path: helpers # store reformated datasets\r\n",
      "temporal_path: temporal # store external data from FTP (temporal because different report dates are used)\r\n",
      "\r\n",
      "\r\n",
      "base_models: # all models and postprocessing path\r\n",
      "    pb_t5esm4500_raw:\r\n",
      "        embeds: \r\n",
      "            - t5\r\n",
      "            - esm_small\r\n",
      "        conditional: false\r\n",
      "        bp: 3000\r\n",
      "        mf: 1000\r\n",
      "        cc: 500\r\n",
      "        \r\n",
      "    pb_t5esm4500_cond:\r\n",
      "        embeds: \r\n",
      "            - t5\r\n",
      "            - esm_small\r\n",
      "        conditional: true\r\n",
      "        bp: 3000\r\n",
      "        mf: 1000\r\n",
      "        cc: 500\r\n",
      "        \r\n",
      "    pb_t54500_raw:\r\n",
      "        embeds: \r\n",
      "            - t5\r\n",
      "        conditional: false\r\n",
      "        bp: 3000\r\n",
      "        mf: 1000\r\n",
      "        cc: 500\r\n",
      "        \r\n",
      "    pb_t54500_cond:\r\n",
      "        embeds: \r\n",
      "            - t5\r\n",
      "        conditional: true\r\n",
      "        bp: 3000\r\n",
      "        mf: 1000\r\n",
      "        cc: 500\r\n",
      "        \r\n",
      "    lin_t5_raw:\r\n",
      "        embeds: \r\n",
      "            - t5\r\n",
      "        conditional: false\r\n",
      "        bp: 10000\r\n",
      "        mf: 2000\r\n",
      "        cc: 1500\r\n",
      "        \r\n",
      "    lin_t5_cond:\r\n",
      "        embeds: \r\n",
      "            - t5\r\n",
      "        conditional: true\r\n",
      "        bp: 10000\r\n",
      "        mf: 2000\r\n",
      "        cc: 1500\r\n",
      "        \r\n",
      "public_models: # models based on public script\r\n",
      "    nn_serg:\r\n",
      "        source: pytorch-keras-etc-3-blend-cafa-metric-etc.pkl\r\n",
      "        # source: test_nn.pkl\r\n",
      "        \r\n",
      "gcn: # stacking with graph neural network - separated by ontology\r\n",
      "    bp:\r\n",
      "        n_ep: 20\r\n",
      "        store_swa: 10\r\n",
      "        use_swa: 3\r\n",
      "        \r\n",
      "        hidden_size: 16\r\n",
      "        n_layers: 8\r\n",
      "        embed_size: 8\r\n",
      "        \r\n",
      "        preds:\r\n",
      "            - pb_t54500_cond\r\n",
      "            - pb_t54500_raw\r\n",
      "            - lin_t5_cond\r\n",
      "            - lin_t5_raw\r\n",
      "            \r\n",
      "        side_preds:\r\n",
      "            - nn_serg\r\n",
      "            \r\n",
      "        tta:\r\n",
      "            cfg0:\r\n",
      "                - pb_t54500_cond\r\n",
      "                - pb_t54500_raw\r\n",
      "                - lin_t5_cond\r\n",
      "                - lin_t5_raw\r\n",
      "            cfg1:\r\n",
      "                - pb_t5esm4500_cond\r\n",
      "                - pb_t54500_raw\r\n",
      "                - lin_t5_cond\r\n",
      "                - lin_t5_raw\r\n",
      "            cfg2:\r\n",
      "                - pb_t54500_cond\r\n",
      "                - pb_t5esm4500_raw\r\n",
      "                - lin_t5_cond\r\n",
      "                - lin_t5_raw\r\n",
      "            cfg3:\r\n",
      "                - pb_t5esm4500_cond\r\n",
      "                - pb_t5esm4500_raw\r\n",
      "                - lin_t5_cond\r\n",
      "                - lin_t5_raw\r\n",
      "\r\n",
      "    mf:\r\n",
      "        n_ep: 20\r\n",
      "        store_swa: 10\r\n",
      "        use_swa: 3\r\n",
      "        \r\n",
      "        hidden_size: 16\r\n",
      "        n_layers: 8\r\n",
      "        embed_size: 8\r\n",
      "        \r\n",
      "        preds:\r\n",
      "            - pb_t54500_cond\r\n",
      "            - pb_t54500_raw\r\n",
      "            - lin_t5_cond\r\n",
      "            - lin_t5_raw\r\n",
      "            \r\n",
      "        side_preds:\r\n",
      "            - nn_serg\r\n",
      "            \r\n",
      "        tta:\r\n",
      "            cfg0:\r\n",
      "                - pb_t54500_cond\r\n",
      "                - pb_t54500_raw\r\n",
      "                - lin_t5_cond\r\n",
      "                - lin_t5_raw\r\n",
      "            cfg1:\r\n",
      "                - pb_t5esm4500_cond\r\n",
      "                - pb_t54500_raw\r\n",
      "                - lin_t5_cond\r\n",
      "                - lin_t5_raw\r\n",
      "            cfg2:\r\n",
      "                - pb_t54500_cond\r\n",
      "                - pb_t5esm4500_raw\r\n",
      "                - lin_t5_cond\r\n",
      "                - lin_t5_raw\r\n",
      "            cfg3:\r\n",
      "                - pb_t5esm4500_cond\r\n",
      "                - pb_t5esm4500_raw\r\n",
      "                - lin_t5_cond\r\n",
      "                - lin_t5_raw\r\n",
      "                \r\n",
      "    cc:\r\n",
      "        n_ep: 20\r\n",
      "        store_swa: 10\r\n",
      "        use_swa: 3\r\n",
      "        \r\n",
      "        hidden_size: 16\r\n",
      "        n_layers: 8\r\n",
      "        embed_size: 8\r\n",
      "        \r\n",
      "        preds:\r\n",
      "            - pb_t54500_cond\r\n",
      "            - pb_t54500_raw\r\n",
      "            - lin_t5_cond\r\n",
      "            - lin_t5_raw\r\n",
      "            \r\n",
      "        side_preds:\r\n",
      "            - nn_serg\r\n",
      "            \r\n",
      "        tta:\r\n",
      "            cfg0:\r\n",
      "                - pb_t54500_cond\r\n",
      "                - pb_t54500_raw\r\n",
      "                - lin_t5_cond\r\n",
      "                - lin_t5_raw\r\n",
      "            cfg1:\r\n",
      "                - pb_t5esm4500_cond\r\n",
      "                - pb_t54500_raw\r\n",
      "                - lin_t5_cond\r\n",
      "                - lin_t5_raw\r\n",
      "            cfg2:\r\n",
      "                - pb_t54500_cond\r\n",
      "                - pb_t5esm4500_raw\r\n",
      "                - lin_t5_cond\r\n",
      "                - lin_t5_raw\r\n",
      "            cfg3:\r\n",
      "                - pb_t5esm4500_cond\r\n",
      "                - pb_t5esm4500_raw\r\n",
      "                - lin_t5_cond\r\n",
      "                - lin_t5_raw\r\n"
     ]
    }
   ],
   "source": [
    "!cat config.yaml\n",
    "\n",
    "with open('config.yaml') as f:\n",
    "    CONFIG = yaml.safe_load(f)\n",
    "    \n",
    "BASE_PATH = CONFIG['base_path']\n",
    "CONFIG_PATH = os.path.join(BASE_PATH, 'config.yaml')\n",
    "RAPIDS_ENV = os.path.join(BASE_PATH, CONFIG['rapids-env'])\n",
    "PYTORCH_ENV = os.path.join(BASE_PATH, CONFIG['pytorch-env'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparation\n",
    "\n",
    "### 1.1. Setup envs\n",
    "\n",
    "Create the following python envs:\n",
    "\n",
    "* `pytorch-env` - env to deal with all DL models\n",
    "* `rapids-env`  - env to preprocess via RAPIDS and train py-boost and logregs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: /home/anton/CAFA5-protein-function-prediction-2nd-place\n",
      "\n",
      "conda 23.5.2\n",
      "Retrieving notices: ...working... done\n",
      "Channels:\n",
      " - rapidsai\n",
      " - conda-forge\n",
      " - nvidia\n",
      " - defaults\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/anton/CAFA5-protein-function-prediction-2nd-place/rapids-env\n",
      "\n",
      "  added / updated specs:\n",
      "    - cuda-version=11.2\n",
      "    - python=3.8\n",
      "    - rapids=23.02\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    c-ares-1.25.0              |       hd590300_0         153 KB  conda-forge\n",
      "    exceptiongroup-1.2.0       |     pyhd8ed1ab_2          20 KB  conda-forge\n",
      "    fastavro-1.9.3             |   py38h01eb140_0         504 KB  conda-forge\n",
      "    fonttools-4.47.2           |   py38h01eb140_0         2.2 MB  conda-forge\n",
      "    jinja2-3.1.3               |     pyhd8ed1ab_0         109 KB  conda-forge\n",
      "    jupyter_core-5.7.1         |   py38h578d9bd_0          77 KB  conda-forge\n",
      "    jupyter_server-2.12.4      |     pyhd8ed1ab_0         313 KB  conda-forge\n",
      "    lz4-4.3.3                  |   py38hdcd8cb4_0          36 KB  conda-forge\n",
      "    markdown-3.5.2             |     pyhd8ed1ab_0          75 KB  conda-forge\n",
      "    nbconvert-core-7.14.1      |     pyhd8ed1ab_0         183 KB  conda-forge\n",
      "    rpds-py-0.17.1             |   py38h0cc4f7c_0         994 KB  conda-forge\n",
      "    wcwidth-0.2.13             |     pyhd8ed1ab_0          32 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         4.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
      "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
      "  aiohttp            conda-forge/linux-64::aiohttp-3.9.1-py38h01eb140_0 \n",
      "  aiosignal          conda-forge/noarch::aiosignal-1.3.1-pyhd8ed1ab_0 \n",
      "  anyio              conda-forge/noarch::anyio-4.2.0-pyhd8ed1ab_0 \n",
      "  aom                conda-forge/linux-64::aom-3.5.0-h27087fc_0 \n",
      "  appdirs            conda-forge/noarch::appdirs-1.4.4-pyh9f0ad1d_0 \n",
      "  argon2-cffi        conda-forge/noarch::argon2-cffi-23.1.0-pyhd8ed1ab_0 \n",
      "  argon2-cffi-bindi~ conda-forge/linux-64::argon2-cffi-bindings-21.2.0-py38h01eb140_4 \n",
      "  arrow              conda-forge/noarch::arrow-1.3.0-pyhd8ed1ab_0 \n",
      "  arrow-cpp          conda-forge/linux-64::arrow-cpp-10.0.1-ha770c72_17_cpu \n",
      "  asttokens          conda-forge/noarch::asttokens-2.4.1-pyhd8ed1ab_0 \n",
      "  async-timeout      conda-forge/noarch::async-timeout-4.0.3-pyhd8ed1ab_0 \n",
      "  attrs              conda-forge/noarch::attrs-23.2.0-pyh71513ae_0 \n",
      "  aws-c-auth         conda-forge/linux-64::aws-c-auth-0.6.26-h987a71b_2 \n",
      "  aws-c-cal          conda-forge/linux-64::aws-c-cal-0.5.21-h48707d8_2 \n",
      "  aws-c-common       conda-forge/linux-64::aws-c-common-0.8.14-h0b41bf4_0 \n",
      "  aws-c-compression  conda-forge/linux-64::aws-c-compression-0.2.16-h03acc5a_5 \n",
      "  aws-c-event-stream conda-forge/linux-64::aws-c-event-stream-0.2.20-h00877a2_4 \n",
      "  aws-c-http         conda-forge/linux-64::aws-c-http-0.7.6-hf342b9f_0 \n",
      "  aws-c-io           conda-forge/linux-64::aws-c-io-0.13.19-h5b20300_3 \n",
      "  aws-c-mqtt         conda-forge/linux-64::aws-c-mqtt-0.8.6-hc4349f7_12 \n",
      "  aws-c-s3           conda-forge/linux-64::aws-c-s3-0.2.7-h909e904_1 \n",
      "  aws-c-sdkutils     conda-forge/linux-64::aws-c-sdkutils-0.1.9-h03acc5a_0 \n",
      "  aws-checksums      conda-forge/linux-64::aws-checksums-0.1.14-h03acc5a_5 \n",
      "  aws-crt-cpp        conda-forge/linux-64::aws-crt-cpp-0.19.8-hf7fbfca_12 \n",
      "  aws-sdk-cpp        conda-forge/linux-64::aws-sdk-cpp-1.10.57-h17c43bd_8 \n",
      "  backcall           conda-forge/noarch::backcall-0.2.0-pyh9f0ad1d_0 \n",
      "  beautifulsoup4     conda-forge/noarch::beautifulsoup4-4.12.2-pyha770c72_0 \n",
      "  bleach             conda-forge/noarch::bleach-6.1.0-pyhd8ed1ab_0 \n",
      "  blosc              conda-forge/linux-64::blosc-1.21.5-h0f2a231_0 \n",
      "  bokeh              conda-forge/noarch::bokeh-2.4.3-pyhd8ed1ab_3 \n",
      "  boost-cpp          conda-forge/linux-64::boost-cpp-1.78.0-h5adbc97_2 \n",
      "  branca             conda-forge/noarch::branca-0.7.0-pyhd8ed1ab_1 \n",
      "  brotli             conda-forge/linux-64::brotli-1.0.9-h166bdaf_9 \n",
      "  brotli-bin         conda-forge/linux-64::brotli-bin-1.0.9-h166bdaf_9 \n",
      "  brotli-python      conda-forge/linux-64::brotli-python-1.0.9-py38hfa26641_9 \n",
      "  brunsli            conda-forge/linux-64::brunsli-0.1-h9c3ff4c_0 \n",
      "  bzip2              conda-forge/linux-64::bzip2-1.0.8-hd590300_5 \n",
      "  c-ares             conda-forge/linux-64::c-ares-1.25.0-hd590300_0 \n",
      "  c-blosc2           conda-forge/linux-64::c-blosc2-2.12.0-hb4ffafa_0 \n",
      "  ca-certificates    conda-forge/linux-64::ca-certificates-2023.11.17-hbcca054_0 \n",
      "  cached-property    conda-forge/noarch::cached-property-1.5.2-hd8ed1ab_1 \n",
      "  cached_property    conda-forge/noarch::cached_property-1.5.2-pyha770c72_1 \n",
      "  cachetools         conda-forge/noarch::cachetools-5.3.2-pyhd8ed1ab_0 \n",
      "  cairo              conda-forge/linux-64::cairo-1.16.0-ha61ee94_1014 \n",
      "  certifi            conda-forge/noarch::certifi-2023.11.17-pyhd8ed1ab_0 \n",
      "  cffi               conda-forge/linux-64::cffi-1.16.0-py38h6d47a40_0 \n",
      "  cfitsio            conda-forge/linux-64::cfitsio-4.2.0-hd9d235c_0 \n",
      "  charls             conda-forge/linux-64::charls-2.3.4-h9c3ff4c_0 \n",
      "  charset-normalizer conda-forge/noarch::charset-normalizer-3.3.2-pyhd8ed1ab_0 \n",
      "  click              conda-forge/noarch::click-8.1.7-unix_pyh707e725_0 \n",
      "  click-plugins      conda-forge/noarch::click-plugins-1.1.1-py_0 \n",
      "  cligj              conda-forge/noarch::cligj-0.7.2-pyhd8ed1ab_1 \n",
      "  cloudpickle        conda-forge/noarch::cloudpickle-3.0.0-pyhd8ed1ab_0 \n",
      "  colorama           conda-forge/noarch::colorama-0.4.6-pyhd8ed1ab_0 \n",
      "  colorcet           conda-forge/noarch::colorcet-3.0.1-pyhd8ed1ab_0 \n",
      "  comm               conda-forge/noarch::comm-0.2.1-pyhd8ed1ab_0 \n",
      "  contourpy          conda-forge/linux-64::contourpy-1.1.1-py38h7f3f72f_1 \n",
      "  cubinlinker        rapidsai/linux-64::cubinlinker-0.3.0-py38hbccff83_0 \n",
      "  cucim              rapidsai/linux-64::cucim-23.02.00-cuda_11_py38_gb8cfaa2_0 \n",
      "  cuda-profiler-api  nvidia/linux-64::cuda-profiler-api-11.8.86-0 \n",
      "  cuda-python        conda-forge/linux-64::cuda-python-11.8.3-py38h1986e8c_0 \n",
      "  cuda-version       conda-forge/noarch::cuda-version-11.2-hb11dac2_2 \n",
      "  cudatoolkit        conda-forge/linux-64::cudatoolkit-11.2.2-hc23eb0c_12 \n",
      "  cudf               rapidsai/linux-64::cudf-23.02.00-cuda_11_py38_g5ad4a85b9d_0 \n",
      "  cudf_kafka         rapidsai/linux-64::cudf_kafka-23.02.00-py38_g5ad4a85b9d_0 \n",
      "  cugraph            rapidsai/linux-64::cugraph-23.02.00-cuda11_py38_g450c25b8_0 \n",
      "  cuml               rapidsai/linux-64::cuml-23.02.00-cuda11_py38_g3356f05bd_0 \n",
      "  cupy               conda-forge/linux-64::cupy-11.6.0-py38h405e1b6_0 \n",
      "  curl               conda-forge/linux-64::curl-8.1.2-h409715c_0 \n",
      "  cusignal           rapidsai/noarch::cusignal-23.02.00-py310_g659a6fa_0 \n",
      "  cuspatial          rapidsai/linux-64::cuspatial-23.02.00-py38_g6fe3841_0 \n",
      "  custreamz          rapidsai/linux-64::custreamz-23.02.00-py38_g5ad4a85b9d_0 \n",
      "  cuxfilter          rapidsai/linux-64::cuxfilter-23.02.00-py38_ge1d1326_0 \n",
      "  cycler             conda-forge/noarch::cycler-0.12.1-pyhd8ed1ab_0 \n",
      "  cyrus-sasl         conda-forge/linux-64::cyrus-sasl-2.1.27-h9033bb2_6 \n",
      "  cytoolz            conda-forge/linux-64::cytoolz-0.12.2-py38h01eb140_1 \n",
      "  dask               conda-forge/noarch::dask-2023.1.1-pyhd8ed1ab_0 \n",
      "  dask-core          conda-forge/noarch::dask-core-2023.1.1-pyhd8ed1ab_0 \n",
      "  dask-cuda          rapidsai/linux-64::dask-cuda-23.02.01-py38_g2c50668_0 \n",
      "  dask-cudf          rapidsai/linux-64::dask-cudf-23.02.00-cuda_11_py38_g5ad4a85b9d_0 \n",
      "  datashader         rapidsai/noarch::datashader-0.13.1a-py_0 \n",
      "  datashape          conda-forge/noarch::datashape-0.5.4-py_1 \n",
      "  dav1d              conda-forge/linux-64::dav1d-1.2.1-hd590300_0 \n",
      "  debugpy            conda-forge/linux-64::debugpy-1.8.0-py38h17151c0_1 \n",
      "  decorator          conda-forge/noarch::decorator-5.1.1-pyhd8ed1ab_0 \n",
      "  defusedxml         conda-forge/noarch::defusedxml-0.7.1-pyhd8ed1ab_0 \n",
      "  distributed        conda-forge/noarch::distributed-2023.1.1-pyhd8ed1ab_0 \n",
      "  dlpack             conda-forge/linux-64::dlpack-0.5-h9c3ff4c_0 \n",
      "  entrypoints        conda-forge/noarch::entrypoints-0.4-pyhd8ed1ab_0 \n",
      "  exceptiongroup     conda-forge/noarch::exceptiongroup-1.2.0-pyhd8ed1ab_2 \n",
      "  executing          conda-forge/noarch::executing-2.0.1-pyhd8ed1ab_0 \n",
      "  expat              conda-forge/linux-64::expat-2.5.0-hcb278e6_1 \n",
      "  faiss-proc         rapidsai/linux-64::faiss-proc-1.0.0-cuda \n",
      "  fastavro           conda-forge/linux-64::fastavro-1.9.3-py38h01eb140_0 \n",
      "  fastrlock          conda-forge/linux-64::fastrlock-0.8.2-py38h17151c0_2 \n",
      "  fiona              conda-forge/linux-64::fiona-1.8.22-py38hc72d8cd_2 \n",
      "  folium             conda-forge/noarch::folium-0.15.1-pyhd8ed1ab_0 \n",
      "  font-ttf-dejavu-s~ conda-forge/noarch::font-ttf-dejavu-sans-mono-2.37-hab24e00_0 \n",
      "  font-ttf-inconsol~ conda-forge/noarch::font-ttf-inconsolata-3.000-h77eed37_0 \n",
      "  font-ttf-source-c~ conda-forge/noarch::font-ttf-source-code-pro-2.038-h77eed37_0 \n",
      "  font-ttf-ubuntu    conda-forge/noarch::font-ttf-ubuntu-0.83-h77eed37_1 \n",
      "  fontconfig         conda-forge/linux-64::fontconfig-2.14.2-h14ed4e7_0 \n",
      "  fonts-conda-ecosy~ conda-forge/noarch::fonts-conda-ecosystem-1-0 \n",
      "  fonts-conda-forge  conda-forge/noarch::fonts-conda-forge-1-0 \n",
      "  fonttools          conda-forge/linux-64::fonttools-4.47.2-py38h01eb140_0 \n",
      "  fqdn               conda-forge/noarch::fqdn-1.5.1-pyhd8ed1ab_0 \n",
      "  freetype           conda-forge/linux-64::freetype-2.12.1-h267a509_2 \n",
      "  freexl             conda-forge/linux-64::freexl-1.0.6-h166bdaf_1 \n",
      "  frozenlist         conda-forge/linux-64::frozenlist-1.4.1-py38h01eb140_0 \n",
      "  fsspec             conda-forge/noarch::fsspec-2023.12.2-pyhca7485f_0 \n",
      "  gdal               conda-forge/linux-64::gdal-3.5.3-py38h58634bd_11 \n",
      "  geopandas          conda-forge/noarch::geopandas-0.13.2-pyhd8ed1ab_1 \n",
      "  geopandas-base     conda-forge/noarch::geopandas-base-0.13.2-pyha770c72_1 \n",
      "  geos               conda-forge/linux-64::geos-3.11.1-h27087fc_0 \n",
      "  geotiff            conda-forge/linux-64::geotiff-1.7.1-h7157cca_5 \n",
      "  gettext            conda-forge/linux-64::gettext-0.21.1-h27087fc_0 \n",
      "  gflags             conda-forge/linux-64::gflags-2.2.2-he1b5a44_1004 \n",
      "  giflib             conda-forge/linux-64::giflib-5.2.1-h0b41bf4_3 \n",
      "  glog               conda-forge/linux-64::glog-0.6.0-h6f12383_0 \n",
      "  hdf4               conda-forge/linux-64::hdf4-4.2.15-h9772cbc_5 \n",
      "  hdf5               conda-forge/linux-64::hdf5-1.12.2-nompi_h4df4325_101 \n",
      "  holoviews          conda-forge/noarch::holoviews-1.15.3-pyhd8ed1ab_0 \n",
      "  icu                conda-forge/linux-64::icu-70.1-h27087fc_0 \n",
      "  idna               conda-forge/noarch::idna-3.6-pyhd8ed1ab_0 \n",
      "  imagecodecs        conda-forge/linux-64::imagecodecs-2022.12.24-py38h7f61701_0 \n",
      "  imageio            conda-forge/noarch::imageio-2.33.1-pyh8c1a49c_0 \n",
      "  importlib-metadata conda-forge/noarch::importlib-metadata-7.0.1-pyha770c72_0 \n",
      "  importlib-resourc~ conda-forge/noarch::importlib-resources-6.1.1-pyhd8ed1ab_0 \n",
      "  importlib_metadata conda-forge/noarch::importlib_metadata-7.0.1-hd8ed1ab_0 \n",
      "  importlib_resourc~ conda-forge/noarch::importlib_resources-6.1.1-pyhd8ed1ab_0 \n",
      "  ipykernel          conda-forge/noarch::ipykernel-6.28.0-pyhd33586a_0 \n",
      "  ipython            conda-forge/noarch::ipython-8.12.2-pyh41d4057_0 \n",
      "  ipywidgets         conda-forge/noarch::ipywidgets-8.1.1-pyhd8ed1ab_0 \n",
      "  isoduration        conda-forge/noarch::isoduration-20.11.0-pyhd8ed1ab_0 \n",
      "  jbig               conda-forge/linux-64::jbig-2.1-h7f98852_2003 \n",
      "  jedi               conda-forge/noarch::jedi-0.19.1-pyhd8ed1ab_0 \n",
      "  jinja2             conda-forge/noarch::jinja2-3.1.3-pyhd8ed1ab_0 \n",
      "  joblib             conda-forge/noarch::joblib-1.3.2-pyhd8ed1ab_0 \n",
      "  jpeg               conda-forge/linux-64::jpeg-9e-h0b41bf4_3 \n",
      "  json-c             conda-forge/linux-64::json-c-0.16-hc379101_0 \n",
      "  jsonpointer        conda-forge/linux-64::jsonpointer-2.4-py38h578d9bd_3 \n",
      "  jsonschema         conda-forge/noarch::jsonschema-4.20.0-pyhd8ed1ab_0 \n",
      "  jsonschema-specif~ conda-forge/noarch::jsonschema-specifications-2023.12.1-pyhd8ed1ab_0 \n",
      "  jsonschema-with-f~ conda-forge/noarch::jsonschema-with-format-nongpl-4.20.0-pyhd8ed1ab_0 \n",
      "  jupyter-server-pr~ conda-forge/noarch::jupyter-server-proxy-4.1.0-pyhd8ed1ab_0 \n",
      "  jupyter_client     conda-forge/noarch::jupyter_client-8.6.0-pyhd8ed1ab_0 \n",
      "  jupyter_core       conda-forge/linux-64::jupyter_core-5.7.1-py38h578d9bd_0 \n",
      "  jupyter_events     conda-forge/noarch::jupyter_events-0.9.0-pyhd8ed1ab_0 \n",
      "  jupyter_server     conda-forge/noarch::jupyter_server-2.12.4-pyhd8ed1ab_0 \n",
      "  jupyter_server_te~ conda-forge/noarch::jupyter_server_terminals-0.5.1-pyhd8ed1ab_0 \n",
      "  jupyterlab_pygmen~ conda-forge/noarch::jupyterlab_pygments-0.3.0-pyhd8ed1ab_0 \n",
      "  jupyterlab_widgets conda-forge/noarch::jupyterlab_widgets-3.0.9-pyhd8ed1ab_0 \n",
      "  jxrlib             conda-forge/linux-64::jxrlib-1.1-hd590300_3 \n",
      "  kealib             conda-forge/linux-64::kealib-1.5.0-ha7026e8_0 \n",
      "  keyutils           conda-forge/linux-64::keyutils-1.6.1-h166bdaf_0 \n",
      "  kiwisolver         conda-forge/linux-64::kiwisolver-1.4.5-py38h7f3f72f_1 \n",
      "  krb5               conda-forge/linux-64::krb5-1.20.1-h81ceb04_0 \n",
      "  lcms2              conda-forge/linux-64::lcms2-2.15-hfd0df8a_0 \n",
      "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.40-h41732ed_0 \n",
      "  lerc               conda-forge/linux-64::lerc-4.0.0-h27087fc_0 \n",
      "  libabseil          conda-forge/linux-64::libabseil-20230125.0-cxx17_hcb278e6_1 \n",
      "  libaec             conda-forge/linux-64::libaec-1.1.2-h59595ed_1 \n",
      "  libarrow           conda-forge/linux-64::libarrow-10.0.1-h51ec05e_17_cpu \n",
      "  libavif            conda-forge/linux-64::libavif-0.11.1-h8182462_2 \n",
      "  libblas            conda-forge/linux-64::libblas-3.9.0-20_linux64_openblas \n",
      "  libbrotlicommon    conda-forge/linux-64::libbrotlicommon-1.0.9-h166bdaf_9 \n",
      "  libbrotlidec       conda-forge/linux-64::libbrotlidec-1.0.9-h166bdaf_9 \n",
      "  libbrotlienc       conda-forge/linux-64::libbrotlienc-1.0.9-h166bdaf_9 \n",
      "  libcblas           conda-forge/linux-64::libcblas-3.9.0-20_linux64_openblas \n",
      "  libcrc32c          conda-forge/linux-64::libcrc32c-1.1.2-h9c3ff4c_0 \n",
      "  libcublas          nvidia/linux-64::libcublas-11.11.3.6-0 \n",
      "  libcublas-dev      nvidia/linux-64::libcublas-dev-11.11.3.6-0 \n",
      "  libcucim           rapidsai/linux-64::libcucim-23.02.00-cuda11_gb8cfaa2_0 \n",
      "  libcudf            rapidsai/linux-64::libcudf-23.02.00-cuda11_g5ad4a85b9d_0 \n",
      "  libcudf_kafka      rapidsai/linux-64::libcudf_kafka-23.02.00-g5ad4a85b9d_0 \n",
      "  libcufft           nvidia/linux-64::libcufft-10.9.0.58-0 \n",
      "  libcugraph         rapidsai/linux-64::libcugraph-23.02.00-cuda11_g450c25b8_0 \n",
      "  libcugraph_etl     rapidsai/linux-64::libcugraph_etl-23.02.00-cuda11_g450c25b8_0 \n",
      "  libcugraphops      nvidia/linux-64::libcugraphops-23.02.01-cuda11_g505ea813_0 \n",
      "  libcuml            rapidsai/linux-64::libcuml-23.02.00-cuda11_g3356f05bd_0 \n",
      "  libcumlprims       nvidia/linux-64::libcumlprims-23.02.00-cuda11_g0c4a914_0 \n",
      "  libcurand          nvidia/linux-64::libcurand-10.3.0.86-0 \n",
      "  libcurand-dev      nvidia/linux-64::libcurand-dev-10.3.0.86-0 \n",
      "  libcurl            conda-forge/linux-64::libcurl-8.1.2-h409715c_0 \n",
      "  libcusolver        nvidia/linux-64::libcusolver-11.4.1.48-0 \n",
      "  libcusolver-dev    nvidia/linux-64::libcusolver-dev-11.4.1.48-0 \n",
      "  libcusparse        nvidia/linux-64::libcusparse-11.7.5.86-0 \n",
      "  libcusparse-dev    nvidia/linux-64::libcusparse-dev-11.7.5.86-0 \n",
      "  libcuspatial       rapidsai/linux-64::libcuspatial-23.02.00-cuda11_g6fe3841_0 \n",
      "  libdap4            conda-forge/linux-64::libdap4-3.20.6-hd7c4107_2 \n",
      "  libdeflate         conda-forge/linux-64::libdeflate-1.14-h166bdaf_0 \n",
      "  libedit            conda-forge/linux-64::libedit-3.1.20191231-he28a2e2_2 \n",
      "  libev              conda-forge/linux-64::libev-4.33-hd590300_2 \n",
      "  libevent           conda-forge/linux-64::libevent-2.1.12-hf998b51_1 \n",
      "  libexpat           conda-forge/linux-64::libexpat-2.5.0-hcb278e6_1 \n",
      "  libfaiss           conda-forge/linux-64::libfaiss-1.7.2-cuda112hb18a002_4_cuda \n",
      "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5 \n",
      "  libgcc-ng          conda-forge/linux-64::libgcc-ng-13.2.0-h807b86a_3 \n",
      "  libgcrypt          conda-forge/linux-64::libgcrypt-1.10.3-hd590300_0 \n",
      "  libgdal            conda-forge/linux-64::libgdal-3.5.3-h05f8703_11 \n",
      "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-13.2.0-h69a702a_3 \n",
      "  libgfortran5       conda-forge/linux-64::libgfortran5-13.2.0-ha4646dd_3 \n",
      "  libglib            conda-forge/linux-64::libglib-2.78.1-hebfc3b9_0 \n",
      "  libgomp            conda-forge/linux-64::libgomp-13.2.0-h807b86a_3 \n",
      "  libgoogle-cloud    conda-forge/linux-64::libgoogle-cloud-2.8.0-h0bc5f78_1 \n",
      "  libgpg-error       conda-forge/linux-64::libgpg-error-1.47-h71f35ed_0 \n",
      "  libgrpc            conda-forge/linux-64::libgrpc-1.52.1-hcf146ea_1 \n",
      "  libgsasl           conda-forge/linux-64::libgsasl-1.8.0-2 \n",
      "  libiconv           conda-forge/linux-64::libiconv-1.17-hd590300_2 \n",
      "  libkml             conda-forge/linux-64::libkml-1.3.0-h01aab08_1016 \n",
      "  liblapack          conda-forge/linux-64::liblapack-3.9.0-20_linux64_openblas \n",
      "  libllvm14          conda-forge/linux-64::libllvm14-14.0.6-hcd5def8_4 \n",
      "  libnetcdf          conda-forge/linux-64::libnetcdf-4.8.1-nompi_h261ec11_106 \n",
      "  libnghttp2         conda-forge/linux-64::libnghttp2-1.58.0-h47da74e_0 \n",
      "  libnsl             conda-forge/linux-64::libnsl-2.0.1-hd590300_0 \n",
      "  libntlm            conda-forge/linux-64::libntlm-1.4-h7f98852_1002 \n",
      "  libopenblas        conda-forge/linux-64::libopenblas-0.3.25-pthreads_h413a1c8_0 \n",
      "  libpng             conda-forge/linux-64::libpng-1.6.39-h753d276_0 \n",
      "  libpq              conda-forge/linux-64::libpq-15.2-hb675445_0 \n",
      "  libprotobuf        conda-forge/linux-64::libprotobuf-3.21.12-hfc55251_2 \n",
      "  libraft-distance   rapidsai/linux-64::libraft-distance-23.02.00-cuda11_g69dce2d4_0 \n",
      "  libraft-headers    rapidsai/linux-64::libraft-headers-23.02.00-cuda11_g69dce2d4_0 \n",
      "  libraft-nn         rapidsai/linux-64::libraft-nn-23.02.00-cuda11_g69dce2d4_0 \n",
      "  librdkafka         conda-forge/linux-64::librdkafka-1.7.0-hb1989a6_1 \n",
      "  librmm             rapidsai/linux-64::librmm-23.02.00-cuda11_g48e8f2a8_0 \n",
      "  librttopo          conda-forge/linux-64::librttopo-1.1.0-ha49c73b_12 \n",
      "  libsodium          conda-forge/linux-64::libsodium-1.0.18-h36c2ea0_1 \n",
      "  libspatialindex    conda-forge/linux-64::libspatialindex-1.9.3-h9c3ff4c_4 \n",
      "  libspatialite      conda-forge/linux-64::libspatialite-5.0.1-h7c8129e_22 \n",
      "  libsqlite          conda-forge/linux-64::libsqlite-3.44.2-h2797004_0 \n",
      "  libssh2            conda-forge/linux-64::libssh2-1.11.0-h0841786_0 \n",
      "  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-13.2.0-h7e041cc_3 \n",
      "  libthrift          conda-forge/linux-64::libthrift-0.18.1-h8fd135c_2 \n",
      "  libtiff            conda-forge/linux-64::libtiff-4.5.0-h82bc61c_0 \n",
      "  libutf8proc        conda-forge/linux-64::libutf8proc-2.8.0-h166bdaf_0 \n",
      "  libuuid            conda-forge/linux-64::libuuid-2.38.1-h0b41bf4_0 \n",
      "  libuv              conda-forge/linux-64::libuv-1.44.2-hd590300_1 \n",
      "  libwebp            pkgs/main/linux-64::libwebp-1.3.2-h11a3e52_0 \n",
      "  libwebp-base       conda-forge/linux-64::libwebp-base-1.3.2-hd590300_0 \n",
      "  libxcb             conda-forge/linux-64::libxcb-1.13-h7f98852_1004 \n",
      "  libxgboost         rapidsai/linux-64::libxgboost-1.7.1dev.rapidsai23.02-cuda_11_2 \n",
      "  libxml2            conda-forge/linux-64::libxml2-2.10.3-hca2bb57_4 \n",
      "  libzip             conda-forge/linux-64::libzip-1.10.1-h2629f0a_3 \n",
      "  libzlib            conda-forge/linux-64::libzlib-1.2.13-hd590300_5 \n",
      "  libzopfli          conda-forge/linux-64::libzopfli-1.0.3-h9c3ff4c_0 \n",
      "  llvmlite           conda-forge/linux-64::llvmlite-0.41.1-py38h94a1851_0 \n",
      "  locket             conda-forge/noarch::locket-1.0.0-pyhd8ed1ab_0 \n",
      "  lz4                conda-forge/linux-64::lz4-4.3.3-py38hdcd8cb4_0 \n",
      "  lz4-c              conda-forge/linux-64::lz4-c-1.9.3-h9c3ff4c_1 \n",
      "  mapclassify        conda-forge/noarch::mapclassify-2.5.0-pyhd8ed1ab_1 \n",
      "  markdown           conda-forge/noarch::markdown-3.5.2-pyhd8ed1ab_0 \n",
      "  markupsafe         conda-forge/linux-64::markupsafe-2.1.3-py38h01eb140_1 \n",
      "  matplotlib-base    conda-forge/linux-64::matplotlib-base-3.7.3-py38h58ed7fa_0 \n",
      "  matplotlib-inline  conda-forge/noarch::matplotlib-inline-0.1.6-pyhd8ed1ab_0 \n",
      "  mistune            conda-forge/noarch::mistune-3.0.2-pyhd8ed1ab_0 \n",
      "  msgpack-python     conda-forge/linux-64::msgpack-python-1.0.7-py38h7f3f72f_0 \n",
      "  multidict          conda-forge/linux-64::multidict-6.0.4-py38h01eb140_1 \n",
      "  multipledispatch   conda-forge/noarch::multipledispatch-0.6.0-py_0 \n",
      "  munch              conda-forge/noarch::munch-4.0.0-pyhd8ed1ab_0 \n",
      "  munkres            conda-forge/noarch::munkres-1.1.4-pyh9f0ad1d_0 \n",
      "  nbclient           conda-forge/noarch::nbclient-0.8.0-pyhd8ed1ab_0 \n",
      "  nbconvert-core     conda-forge/noarch::nbconvert-core-7.14.1-pyhd8ed1ab_0 \n",
      "  nbformat           conda-forge/noarch::nbformat-5.9.2-pyhd8ed1ab_0 \n",
      "  nccl               conda-forge/linux-64::nccl-2.19.4.1-h0800d71_0 \n",
      "  ncurses            conda-forge/linux-64::ncurses-6.4-h59595ed_2 \n",
      "  nest-asyncio       conda-forge/noarch::nest-asyncio-1.5.8-pyhd8ed1ab_0 \n",
      "  networkx           conda-forge/noarch::networkx-3.1-pyhd8ed1ab_0 \n",
      "  nodejs             conda-forge/linux-64::nodejs-18.15.0-h8d033a5_0 \n",
      "  nspr               conda-forge/linux-64::nspr-4.35-h27087fc_0 \n",
      "  nss                conda-forge/linux-64::nss-3.96-h1d7d5a4_0 \n",
      "  numba              conda-forge/linux-64::numba-0.58.1-py38h4144172_0 \n",
      "  numpy              conda-forge/linux-64::numpy-1.23.5-py38h7042d01_0 \n",
      "  nvtx               conda-forge/linux-64::nvtx-0.2.8-py38h01eb140_1 \n",
      "  openjpeg           conda-forge/linux-64::openjpeg-2.5.0-hfec8fc6_2 \n",
      "  openssl            conda-forge/linux-64::openssl-3.1.4-hd590300_0 \n",
      "  orc                conda-forge/linux-64::orc-1.8.3-h2f23424_1 \n",
      "  overrides          conda-forge/noarch::overrides-7.4.0-pyhd8ed1ab_0 \n",
      "  packaging          conda-forge/noarch::packaging-23.2-pyhd8ed1ab_0 \n",
      "  pandas             conda-forge/linux-64::pandas-1.5.3-py38hdc8b05c_1 \n",
      "  pandocfilters      conda-forge/noarch::pandocfilters-1.5.0-pyhd8ed1ab_0 \n",
      "  panel              conda-forge/noarch::panel-0.14.1-pyhd8ed1ab_0 \n",
      "  param              conda-forge/noarch::param-1.13.0-pyh1a96a4e_0 \n",
      "  parquet-cpp        conda-forge/noarch::parquet-cpp-1.5.1-2 \n",
      "  parso              conda-forge/noarch::parso-0.8.3-pyhd8ed1ab_0 \n",
      "  partd              conda-forge/noarch::partd-1.4.1-pyhd8ed1ab_0 \n",
      "  pcre2              conda-forge/linux-64::pcre2-10.40-hc3806b6_0 \n",
      "  pexpect            conda-forge/noarch::pexpect-4.8.0-pyh1a96a4e_2 \n",
      "  pickleshare        conda-forge/noarch::pickleshare-0.7.5-py_1003 \n",
      "  pillow             conda-forge/linux-64::pillow-9.4.0-py38hde6dc18_1 \n",
      "  pip                conda-forge/noarch::pip-23.3.2-pyhd8ed1ab_0 \n",
      "  pixman             conda-forge/linux-64::pixman-0.43.0-h59595ed_0 \n",
      "  pkgutil-resolve-n~ conda-forge/noarch::pkgutil-resolve-name-1.3.10-pyhd8ed1ab_1 \n",
      "  platformdirs       conda-forge/noarch::platformdirs-4.1.0-pyhd8ed1ab_0 \n",
      "  pooch              conda-forge/noarch::pooch-1.8.0-pyhd8ed1ab_0 \n",
      "  poppler            conda-forge/linux-64::poppler-22.12.0-h091648b_1 \n",
      "  poppler-data       conda-forge/noarch::poppler-data-0.4.12-hd8ed1ab_0 \n",
      "  postgresql         conda-forge/linux-64::postgresql-15.2-h3248436_0 \n",
      "  proj               conda-forge/linux-64::proj-9.1.0-h8ffa02c_1 \n",
      "  prometheus_client  conda-forge/noarch::prometheus_client-0.19.0-pyhd8ed1ab_0 \n",
      "  prompt-toolkit     conda-forge/noarch::prompt-toolkit-3.0.42-pyha770c72_0 \n",
      "  prompt_toolkit     conda-forge/noarch::prompt_toolkit-3.0.42-hd8ed1ab_0 \n",
      "  protobuf           conda-forge/linux-64::protobuf-4.21.12-py38h8dc9893_0 \n",
      "  psutil             conda-forge/linux-64::psutil-5.9.7-py38h01eb140_0 \n",
      "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h36c2ea0_1001 \n",
      "  ptxcompiler        conda-forge/linux-64::ptxcompiler-0.8.1-py38h1986e8c_2 \n",
      "  ptyprocess         conda-forge/noarch::ptyprocess-0.7.0-pyhd3deb0d_0 \n",
      "  pure_eval          conda-forge/noarch::pure_eval-0.2.2-pyhd8ed1ab_0 \n",
      "  py-xgboost         rapidsai/linux-64::py-xgboost-1.7.1dev.rapidsai23.02-cuda_11_py38_2 \n",
      "  pyarrow            conda-forge/linux-64::pyarrow-10.0.1-py38hf05218d_17_cpu \n",
      "  pycparser          conda-forge/noarch::pycparser-2.21-pyhd8ed1ab_0 \n",
      "  pyct               conda-forge/noarch::pyct-0.5.0-pyhd8ed1ab_0 \n",
      "  pydeck             conda-forge/noarch::pydeck-0.5.0-pyh9f0ad1d_0 \n",
      "  pyee               conda-forge/noarch::pyee-8.1.0-pyhd8ed1ab_0 \n",
      "  pygments           conda-forge/noarch::pygments-2.17.2-pyhd8ed1ab_0 \n",
      "  pylibcugraph       rapidsai/linux-64::pylibcugraph-23.02.00-cuda11_py38_g450c25b8_0 \n",
      "  pylibraft          rapidsai/linux-64::pylibraft-23.02.00-cuda11_py38_g69dce2d4_0 \n",
      "  pynvml             conda-forge/noarch::pynvml-11.4.1-pyhd8ed1ab_0 \n",
      "  pyparsing          conda-forge/noarch::pyparsing-3.1.1-pyhd8ed1ab_0 \n",
      "  pyppeteer          conda-forge/noarch::pyppeteer-1.0.2-pyhd8ed1ab_0 \n",
      "  pyproj             conda-forge/linux-64::pyproj-3.4.0-py38hce0a2d1_2 \n",
      "  pysocks            conda-forge/noarch::pysocks-1.7.1-pyha2e5f31_6 \n",
      "  python             conda-forge/linux-64::python-3.8.18-hd12c33a_0_cpython \n",
      "  python-confluent-~ conda-forge/linux-64::python-confluent-kafka-1.7.0-py38h497a2fe_2 \n",
      "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.2-pyhd8ed1ab_0 \n",
      "  python-fastjsonsc~ conda-forge/noarch::python-fastjsonschema-2.19.1-pyhd8ed1ab_0 \n",
      "  python-json-logger conda-forge/noarch::python-json-logger-2.0.7-pyhd8ed1ab_0 \n",
      "  python_abi         conda-forge/linux-64::python_abi-3.8-4_cp38 \n",
      "  pytz               conda-forge/noarch::pytz-2023.3.post1-pyhd8ed1ab_0 \n",
      "  pyviz_comms        conda-forge/noarch::pyviz_comms-3.0.0-pyhd8ed1ab_0 \n",
      "  pywavelets         conda-forge/linux-64::pywavelets-1.4.1-py38h7f0c24c_1 \n",
      "  pyyaml             conda-forge/linux-64::pyyaml-6.0.1-py38h01eb140_1 \n",
      "  pyzmq              conda-forge/linux-64::pyzmq-25.1.2-py38h34c975a_0 \n",
      "  raft-dask          rapidsai/linux-64::raft-dask-23.02.00-cuda11_py38_g69dce2d4_0 \n",
      "  rapids             rapidsai/linux-64::rapids-23.02.00-cuda11_py38_g87dd3f4_144 \n",
      "  rapids-xgboost     rapidsai/linux-64::rapids-xgboost-23.02.00-cuda11_py38_g87dd3f4_144 \n",
      "  re2                conda-forge/linux-64::re2-2023.02.02-hcb278e6_0 \n",
      "  readline           conda-forge/linux-64::readline-8.2-h8228510_1 \n",
      "  referencing        conda-forge/noarch::referencing-0.32.1-pyhd8ed1ab_0 \n",
      "  requests           conda-forge/noarch::requests-2.31.0-pyhd8ed1ab_0 \n",
      "  rfc3339-validator  conda-forge/noarch::rfc3339-validator-0.1.4-pyhd8ed1ab_0 \n",
      "  rfc3986-validator  conda-forge/noarch::rfc3986-validator-0.1.1-pyh9f0ad1d_0 \n",
      "  rmm                rapidsai/linux-64::rmm-23.02.00-cuda11_py38_g48e8f2a8_0 \n",
      "  rpds-py            conda-forge/linux-64::rpds-py-0.17.1-py38h0cc4f7c_0 \n",
      "  rtree              conda-forge/linux-64::rtree-1.1.0-py38h02d302b_0 \n",
      "  s2n                conda-forge/linux-64::s2n-1.3.41-h3358134_0 \n",
      "  scikit-image       conda-forge/linux-64::scikit-image-0.19.3-py38h8f669ce_2 \n",
      "  scikit-learn       conda-forge/linux-64::scikit-learn-1.3.2-py38ha25d942_2 \n",
      "  scipy              conda-forge/linux-64::scipy-1.10.1-py38h59b608b_3 \n",
      "  send2trash         conda-forge/noarch::send2trash-1.8.2-pyh41d4057_0 \n",
      "  setuptools         conda-forge/noarch::setuptools-69.0.3-pyhd8ed1ab_0 \n",
      "  shapely            conda-forge/linux-64::shapely-2.0.1-py38hd07e089_0 \n",
      "  simpervisor        conda-forge/noarch::simpervisor-1.0.0-pyhd8ed1ab_0 \n",
      "  six                conda-forge/noarch::six-1.16.0-pyh6c4a22f_0 \n",
      "  snappy             conda-forge/linux-64::snappy-1.1.10-h9fff704_0 \n",
      "  sniffio            conda-forge/noarch::sniffio-1.3.0-pyhd8ed1ab_0 \n",
      "  sortedcontainers   conda-forge/noarch::sortedcontainers-2.4.0-pyhd8ed1ab_0 \n",
      "  soupsieve          conda-forge/noarch::soupsieve-2.5-pyhd8ed1ab_1 \n",
      "  spdlog             conda-forge/linux-64::spdlog-1.8.5-h4bd325d_1 \n",
      "  sqlite             conda-forge/linux-64::sqlite-3.44.2-h2c6b66d_0 \n",
      "  stack_data         conda-forge/noarch::stack_data-0.6.2-pyhd8ed1ab_0 \n",
      "  streamz            conda-forge/noarch::streamz-0.6.4-pyh6c4a22f_0 \n",
      "  tblib              conda-forge/noarch::tblib-3.0.0-pyhd8ed1ab_0 \n",
      "  terminado          conda-forge/noarch::terminado-0.18.0-pyh0d859eb_0 \n",
      "  threadpoolctl      conda-forge/noarch::threadpoolctl-3.2.0-pyha21a80b_0 \n",
      "  tifffile           conda-forge/noarch::tifffile-2022.10.10-pyhd8ed1ab_0 \n",
      "  tiledb             conda-forge/linux-64::tiledb-2.13.2-hd532e3d_0 \n",
      "  tinycss2           conda-forge/noarch::tinycss2-1.2.1-pyhd8ed1ab_0 \n",
      "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_h4845f30_101 \n",
      "  toolz              conda-forge/noarch::toolz-0.12.0-pyhd8ed1ab_0 \n",
      "  tornado            conda-forge/linux-64::tornado-6.3.3-py38h01eb140_1 \n",
      "  tqdm               conda-forge/noarch::tqdm-4.66.1-pyhd8ed1ab_0 \n",
      "  traitlets          conda-forge/noarch::traitlets-5.14.1-pyhd8ed1ab_0 \n",
      "  treelite           conda-forge/linux-64::treelite-3.1.0-py38h2820b77_0 \n",
      "  types-python-date~ conda-forge/noarch::types-python-dateutil-2.8.19.20240106-pyhd8ed1ab_0 \n",
      "  typing-extensions  conda-forge/noarch::typing-extensions-4.9.0-hd8ed1ab_0 \n",
      "  typing_extensions  conda-forge/noarch::typing_extensions-4.9.0-pyha770c72_0 \n",
      "  typing_utils       conda-forge/noarch::typing_utils-0.1.0-pyhd8ed1ab_0 \n",
      "  tzcode             conda-forge/linux-64::tzcode-2023d-h3f72095_0 \n",
      "  tzdata             conda-forge/noarch::tzdata-2023d-h0c530f3_0 \n",
      "  ucx                conda-forge/linux-64::ucx-1.13.1-h538f049_1 \n",
      "  ucx-proc           rapidsai/linux-64::ucx-proc-1.0.0-gpu \n",
      "  ucx-py             rapidsai/linux-64::ucx-py-0.30.00-py38_gc2651fc_0 \n",
      "  unicodedata2       conda-forge/linux-64::unicodedata2-15.1.0-py38h01eb140_0 \n",
      "  uri-template       conda-forge/noarch::uri-template-1.3.0-pyhd8ed1ab_0 \n",
      "  uriparser          conda-forge/linux-64::uriparser-0.9.7-hcb278e6_1 \n",
      "  urllib3            conda-forge/noarch::urllib3-1.26.18-pyhd8ed1ab_0 \n",
      "  wcwidth            conda-forge/noarch::wcwidth-0.2.13-pyhd8ed1ab_0 \n",
      "  webcolors          conda-forge/noarch::webcolors-1.13-pyhd8ed1ab_0 \n",
      "  webencodings       conda-forge/noarch::webencodings-0.5.1-pyhd8ed1ab_2 \n",
      "  websocket-client   conda-forge/noarch::websocket-client-1.7.0-pyhd8ed1ab_0 \n",
      "  websockets         conda-forge/linux-64::websockets-10.4-py38h0a891b7_1 \n",
      "  wheel              conda-forge/noarch::wheel-0.42.0-pyhd8ed1ab_0 \n",
      "  widgetsnbextension conda-forge/noarch::widgetsnbextension-4.0.9-pyhd8ed1ab_0 \n",
      "  xarray             conda-forge/noarch::xarray-2023.1.0-pyhd8ed1ab_0 \n",
      "  xerces-c           conda-forge/linux-64::xerces-c-3.2.4-h55805fa_1 \n",
      "  xgboost            rapidsai/linux-64::xgboost-1.7.1dev.rapidsai23.02-cuda_11_py38_2 \n",
      "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h7f98852_1002 \n",
      "  xorg-libice        conda-forge/linux-64::xorg-libice-1.1.1-hd590300_0 \n",
      "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.4-h7391055_0 \n",
      "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.8.4-h0b41bf4_0 \n",
      "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.11-hd590300_0 \n",
      "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h7f98852_0 \n",
      "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h0b41bf4_2 \n",
      "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h7f98852_1003 \n",
      "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h7f98852_1002 \n",
      "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h0b41bf4_1003 \n",
      "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h7f98852_1007 \n",
      "  xyzservices        conda-forge/noarch::xyzservices-2023.10.1-pyhd8ed1ab_0 \n",
      "  xz                 conda-forge/linux-64::xz-5.2.6-h166bdaf_0 \n",
      "  yaml               conda-forge/linux-64::yaml-0.2.5-h7f98852_2 \n",
      "  yarl               conda-forge/linux-64::yarl-1.9.3-py38h01eb140_0 \n",
      "  zeromq             conda-forge/linux-64::zeromq-4.3.5-h59595ed_0 \n",
      "  zfp                conda-forge/linux-64::zfp-1.0.1-h59595ed_0 \n",
      "  zict               conda-forge/noarch::zict-3.0.0-pyhd8ed1ab_0 \n",
      "  zipp               conda-forge/noarch::zipp-3.17.0-pyhd8ed1ab_0 \n",
      "  zlib               conda-forge/linux-64::zlib-1.2.13-hd590300_5 \n",
      "  zlib-ng            conda-forge/linux-64::zlib-ng-2.0.7-h0b41bf4_0 \n",
      "  zstd               conda-forge/linux-64::zstd-1.5.5-hfc55251_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exceptiongroup-1.2.0 | 20 KB     |                                       |   0% \n",
      "jupyter_server-2.12. | 313 KB    |                                       |   0% \u001b[A\n",
      "\n",
      "jinja2-3.1.3         | 109 KB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "fonttools-4.47.2     | 2.2 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "markdown-3.5.2       | 75 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "rpds-py-0.17.1       | 994 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wcwidth-0.2.13       | 32 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lz4-4.3.3            | 36 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "jupyter_core-5.7.1   | 77 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fastavro-1.9.3       | 504 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nbconvert-core-7.14. | 183 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "exceptiongroup-1.2.0 | 20 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "fonttools-4.47.2     | 2.2 MB    | 2                                     |   1% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wcwidth-0.2.13       | 32 KB     | ##################5                   |  50% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "jinja2-3.1.3         | 109 KB    | #####4                                |  15% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "rpds-py-0.17.1       | 994 KB    | 5                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "markdown-3.5.2       | 75 KB     | #######8                              |  21% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wcwidth-0.2.13       | 32 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lz4-4.3.3            | 36 KB     | ################2                     |  44% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nbconvert-core-7.14. | 183 KB    | ###2                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "jinja2-3.1.3         | 109 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "jinja2-3.1.3         | 109 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "jupyter_server-2.12. | 313 KB    | #8                                    |   5% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "c-ares-1.25.0        | 153 KB    | ###8                                  |  10% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "jupyter_core-5.7.1   | 77 KB     | #######6                              |  21% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "markdown-3.5.2       | 75 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "markdown-3.5.2       | 75 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lz4-4.3.3            | 36 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lz4-4.3.3            | 36 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "rpds-py-0.17.1       | 994 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "rpds-py-0.17.1       | 994 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fastavro-1.9.3       | 504 KB    | #1                                    |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nbconvert-core-7.14. | 183 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nbconvert-core-7.14. | 183 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "c-ares-1.25.0        | 153 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "c-ares-1.25.0        | 153 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "jupyter_core-5.7.1   | 77 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "jupyter_core-5.7.1   | 77 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "jupyter_server-2.12. | 313 KB    | ##################################### | 100% \u001b[A\n",
      "jupyter_server-2.12. | 313 KB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fastavro-1.9.3       | 504 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fastavro-1.9.3       | 504 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "fonttools-4.47.2     | 2.2 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "\n",
      "\n",
      "The following PRELINK MESSAGES are INCLUDED:\n",
      "\n",
      "\n",
      "  File nvcomp.txt:\n",
      "\n",
      "  By downloading and using the libcudf conda package, you accept the terms\n",
      "  and conditions of the NVIDIA NVCOMP Software License Agreement:\n",
      "    https://developer.download.nvidia.com/compute/nvcomp/2.3/LICENSE.txt\n",
      "\n",
      "\n",
      "Executing transaction: | By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
      "\n",
      "\\ By downloading and using the CubinLinker conda packages, you accept the terms and conditions of the CubinLinker License Agreement: https://docs.rapids.ai/licenses/CubinLinker.txt\n",
      "\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /home/anton/CAFA5-protein-function-prediction-2nd-place/rapids-env\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "/home/anton/CAFA5-protein-function-prediction-2nd-place/rapids-env/bin/python\n",
      "Found existing installation: cupy 11.6.0\n",
      "Uninstalling cupy-11.6.0:\n",
      "  Successfully uninstalled cupy-11.6.0\n",
      "Found existing installation: numba 0.58.1\n",
      "Uninstalling numba-0.58.1:\n",
      "  Successfully uninstalled numba-0.58.1\n",
      "Requirement already satisfied: tqdm in ./rapids-env/lib/python3.8/site-packages (4.66.1)\n",
      "Collecting cupy-cuda112==10.6\n",
      "  Using cached cupy_cuda112-10.6.0-cp38-cp38-manylinux1_x86_64.whl (80.8 MB)\n",
      "Collecting numba==0.56.4\n",
      "  Using cached numba-0.56.4-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "Collecting py-boost==0.4.3\n",
      "  Using cached py_boost-0.4.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy<1.25,>=1.18 in ./rapids-env/lib/python3.8/site-packages (from cupy-cuda112==10.6) (1.23.5)\n",
      "Requirement already satisfied: fastrlock>=0.5 in ./rapids-env/lib/python3.8/site-packages (from cupy-cuda112==10.6) (0.8.2)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0 (from numba==0.56.4)\n",
      "  Using cached llvmlite-0.39.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
      "Requirement already satisfied: setuptools in ./rapids-env/lib/python3.8/site-packages (from numba==0.56.4) (69.0.3)\n",
      "Requirement already satisfied: importlib-metadata in ./rapids-env/lib/python3.8/site-packages (from numba==0.56.4) (7.0.1)\n",
      "Requirement already satisfied: joblib in ./rapids-env/lib/python3.8/site-packages (from py-boost==0.4.3) (1.3.2)\n",
      "Requirement already satisfied: pandas>=1 in ./rapids-env/lib/python3.8/site-packages (from py-boost==0.4.3) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn>=1 in ./rapids-env/lib/python3.8/site-packages (from py-boost==0.4.3) (1.3.2)\n",
      "Requirement already satisfied: treelite<4,>=3 in ./rapids-env/lib/python3.8/site-packages (from py-boost==0.4.3) (3.1.0)\n",
      "Requirement already satisfied: treelite_runtime<4,>=3 in ./rapids-env/lib/python3.8/site-packages (from py-boost==0.4.3) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./rapids-env/lib/python3.8/site-packages (from pandas>=1->py-boost==0.4.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./rapids-env/lib/python3.8/site-packages (from pandas>=1->py-boost==0.4.3) (2023.3.post1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy>=1.5.0 in ./rapids-env/lib/python3.8/site-packages (from scikit-learn>=1->py-boost==0.4.3) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./rapids-env/lib/python3.8/site-packages (from scikit-learn>=1->py-boost==0.4.3) (3.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./rapids-env/lib/python3.8/site-packages (from importlib-metadata->numba==0.56.4) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in ./rapids-env/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas>=1->py-boost==0.4.3) (1.16.0)\n",
      "Using cached py_boost-0.4.3-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: llvmlite, cupy-cuda112, numba, py-boost\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.41.1\n",
      "    Uninstalling llvmlite-0.41.1:\n",
      "      Successfully uninstalled llvmlite-0.41.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 23.2.0 requires cupy-cuda11x, which is not installed.\n",
      "cudf-kafka 23.2.0 requires cython, which is not installed.\n",
      "cugraph 23.2.0+0.g450c25b8.dirty requires cupy-cuda11x, which is not installed.\n",
      "cuml 23.2.0 requires seaborn, which is not installed.\n",
      "dask-cudf 23.2.0 requires cupy-cuda11x, which is not installed.\n",
      "cudf 23.2.0 requires protobuf==4.21, but you have protobuf 4.21.12 which is incompatible.\n",
      "cudf 23.2.0 requires pyarrow==10, but you have pyarrow 10.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cupy-cuda112-10.6.0 llvmlite-0.39.1 numba-0.56.4 py-boost-0.4.3\n",
      "/home/anton/CAFA5-protein-function-prediction-2nd-place\n",
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: /home/anton/CAFA5-protein-function-prediction-2nd-place\n",
      "\n",
      "conda 23.5.2\n",
      "Channels:\n",
      " - defaults\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/anton/CAFA5-protein-function-prediction-2nd-place/pytorch-env\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.9\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
      "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n",
      "  ca-certificates    pkgs/main/linux-64::ca-certificates-2023.12.12-h06a4308_0 \n",
      "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.38-h1181459_1 \n",
      "  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_0 \n",
      "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n",
      "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n",
      "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n",
      "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 \n",
      "  openssl            pkgs/main/linux-64::openssl-3.0.12-h7f8727e_0 \n",
      "  pip                pkgs/main/linux-64::pip-23.3.1-py39h06a4308_0 \n",
      "  python             pkgs/main/linux-64::python-3.9.18-h955ad1f_0 \n",
      "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 \n",
      "  setuptools         pkgs/main/linux-64::setuptools-68.2.2-py39h06a4308_0 \n",
      "  sqlite             pkgs/main/linux-64::sqlite-3.41.2-h5eee18b_0 \n",
      "  tk                 pkgs/main/linux-64::tk-8.6.12-h1ccaba5_0 \n",
      "  tzdata             pkgs/main/noarch::tzdata-2023d-h04d1e81_0 \n",
      "  wheel              pkgs/main/linux-64::wheel-0.41.2-py39h06a4308_0 \n",
      "  xz                 pkgs/main/linux-64::xz-5.4.5-h5eee18b_0 \n",
      "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /home/anton/CAFA5-protein-function-prediction-2nd-place/pytorch-env\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "Channels:\n",
      " - pytorch\n",
      " - nvidia\n",
      " - defaults\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/anton/CAFA5-protein-function-prediction-2nd-place/pytorch-env\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch-cuda=11.8\n",
      "    - pytorch==2.0.1\n",
      "    - torchaudio==2.0.2\n",
      "    - torchvision==0.15.2\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  blas               pkgs/main/linux-64::blas-1.0-mkl \n",
      "  brotli-python      pkgs/main/linux-64::brotli-python-1.0.9-py39h6a678d5_7 \n",
      "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h7b6447c_0 \n",
      "  certifi            pkgs/main/linux-64::certifi-2023.11.17-py39h06a4308_0 \n",
      "  cffi               pkgs/main/linux-64::cffi-1.16.0-py39h5eee18b_0 \n",
      "  charset-normalizer pkgs/main/noarch::charset-normalizer-2.0.4-pyhd3eb1b0_0 \n",
      "  cryptography       pkgs/main/linux-64::cryptography-41.0.7-py39hdda0065_0 \n",
      "  cuda-cudart        nvidia/linux-64::cuda-cudart-11.8.89-0 \n",
      "  cuda-cupti         nvidia/linux-64::cuda-cupti-11.8.87-0 \n",
      "  cuda-libraries     nvidia/linux-64::cuda-libraries-11.8.0-0 \n",
      "  cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-11.8.89-0 \n",
      "  cuda-nvtx          nvidia/linux-64::cuda-nvtx-11.8.86-0 \n",
      "  cuda-runtime       nvidia/linux-64::cuda-runtime-11.8.0-0 \n",
      "  ffmpeg             pytorch/linux-64::ffmpeg-4.3-hf484d3e_0 \n",
      "  filelock           pkgs/main/linux-64::filelock-3.13.1-py39h06a4308_0 \n",
      "  freetype           pkgs/main/linux-64::freetype-2.12.1-h4a9f257_0 \n",
      "  giflib             pkgs/main/linux-64::giflib-5.2.1-h5eee18b_3 \n",
      "  gmp                pkgs/main/linux-64::gmp-6.2.1-h295c915_3 \n",
      "  gmpy2              pkgs/main/linux-64::gmpy2-2.1.2-py39heeb90bb_0 \n",
      "  gnutls             pkgs/main/linux-64::gnutls-3.6.15-he1e5248_0 \n",
      "  idna               pkgs/main/linux-64::idna-3.4-py39h06a4308_0 \n",
      "  intel-openmp       pkgs/main/linux-64::intel-openmp-2023.1.0-hdb19cb5_46306 \n",
      "  jinja2             pkgs/main/linux-64::jinja2-3.1.2-py39h06a4308_0 \n",
      "  jpeg               pkgs/main/linux-64::jpeg-9e-h5eee18b_1 \n",
      "  lame               pkgs/main/linux-64::lame-3.100-h7b6447c_0 \n",
      "  lcms2              pkgs/main/linux-64::lcms2-2.12-h3be6417_0 \n",
      "  lerc               pkgs/main/linux-64::lerc-3.0-h295c915_0 \n",
      "  libcublas          nvidia/linux-64::libcublas-11.11.3.6-0 \n",
      "  libcufft           nvidia/linux-64::libcufft-10.9.0.58-0 \n",
      "  libcufile          nvidia/linux-64::libcufile-1.8.1.2-0 \n",
      "  libcurand          nvidia/linux-64::libcurand-10.3.4.107-0 \n",
      "  libcusolver        nvidia/linux-64::libcusolver-11.4.1.48-0 \n",
      "  libcusparse        nvidia/linux-64::libcusparse-11.7.5.86-0 \n",
      "  libdeflate         pkgs/main/linux-64::libdeflate-1.17-h5eee18b_1 \n",
      "  libiconv           pkgs/main/linux-64::libiconv-1.16-h7f8727e_2 \n",
      "  libidn2            pkgs/main/linux-64::libidn2-2.3.4-h5eee18b_0 \n",
      "  libnpp             nvidia/linux-64::libnpp-11.8.0.86-0 \n",
      "  libnvjpeg          nvidia/linux-64::libnvjpeg-11.9.0.86-0 \n",
      "  libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 \n",
      "  libtasn1           pkgs/main/linux-64::libtasn1-4.19.0-h5eee18b_0 \n",
      "  libtiff            pkgs/main/linux-64::libtiff-4.5.1-h6a678d5_0 \n",
      "  libunistring       pkgs/main/linux-64::libunistring-0.9.10-h27cfd23_0 \n",
      "  libwebp            pkgs/main/linux-64::libwebp-1.3.2-h11a3e52_0 \n",
      "  libwebp-base       pkgs/main/linux-64::libwebp-base-1.3.2-h5eee18b_0 \n",
      "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.4-h6a678d5_0 \n",
      "  markupsafe         pkgs/main/linux-64::markupsafe-2.1.3-py39h5eee18b_0 \n",
      "  mkl                pkgs/main/linux-64::mkl-2023.1.0-h213fc3f_46344 \n",
      "  mkl-service        pkgs/main/linux-64::mkl-service-2.4.0-py39h5eee18b_1 \n",
      "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.3.8-py39h5eee18b_0 \n",
      "  mkl_random         pkgs/main/linux-64::mkl_random-1.2.4-py39hdb19cb5_0 \n",
      "  mpc                pkgs/main/linux-64::mpc-1.1.0-h10f8cd9_1 \n",
      "  mpfr               pkgs/main/linux-64::mpfr-4.0.2-hb69a4c5_1 \n",
      "  mpmath             pkgs/main/linux-64::mpmath-1.3.0-py39h06a4308_0 \n",
      "  nettle             pkgs/main/linux-64::nettle-3.7.3-hbbd107a_1 \n",
      "  networkx           pkgs/main/linux-64::networkx-3.1-py39h06a4308_0 \n",
      "  numpy              pkgs/main/linux-64::numpy-1.26.3-py39h5f9d8c6_0 \n",
      "  numpy-base         pkgs/main/linux-64::numpy-base-1.26.3-py39hb5e798b_0 \n",
      "  openh264           pkgs/main/linux-64::openh264-2.1.1-h4ff587b_0 \n",
      "  openjpeg           pkgs/main/linux-64::openjpeg-2.4.0-h3ad879b_0 \n",
      "  pillow             pkgs/main/linux-64::pillow-10.0.1-py39ha6cbd5a_0 \n",
      "  pycparser          pkgs/main/noarch::pycparser-2.21-pyhd3eb1b0_0 \n",
      "  pyopenssl          pkgs/main/linux-64::pyopenssl-23.2.0-py39h06a4308_0 \n",
      "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py39h06a4308_0 \n",
      "  pytorch            pytorch/linux-64::pytorch-2.0.1-py3.9_cuda11.8_cudnn8.7.0_0 \n",
      "  pytorch-cuda       pytorch/linux-64::pytorch-cuda-11.8-h7e8668a_5 \n",
      "  pytorch-mutex      pytorch/noarch::pytorch-mutex-1.0-cuda \n",
      "  requests           pkgs/main/linux-64::requests-2.31.0-py39h06a4308_0 \n",
      "  sympy              pkgs/main/linux-64::sympy-1.12-py39h06a4308_0 \n",
      "  tbb                pkgs/main/linux-64::tbb-2021.8.0-hdb19cb5_0 \n",
      "  torchaudio         pytorch/linux-64::torchaudio-2.0.2-py39_cu118 \n",
      "  torchtriton        pytorch/linux-64::torchtriton-2.0.0-py39 \n",
      "  torchvision        pytorch/linux-64::torchvision-0.15.2-py39_cu118 \n",
      "  typing_extensions  pkgs/main/linux-64::typing_extensions-4.9.0-py39h06a4308_0 \n",
      "  urllib3            pkgs/main/linux-64::urllib3-1.26.18-py39h06a4308_0 \n",
      "  zstd               pkgs/main/linux-64::zstd-1.5.5-hc292b87_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      " - nvidia\n",
      " - pytorch\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/anton/CAFA5-protein-function-prediction-2nd-place/pytorch-env\n",
      "\n",
      "  added / updated specs:\n",
      "    - cupy\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cuda-version       conda-forge/noarch::cuda-version-10.2-h4767cc1_2 \n",
      "  cudatoolkit        conda-forge/linux-64::cudatoolkit-10.2.89-h713d32c_10 \n",
      "  cupy               conda-forge/linux-64::cupy-12.1.0-py39h98de0c3_0 \n",
      "  fastrlock          conda-forge/linux-64::fastrlock-0.8-py39h5a03fae_2 \n",
      "  python_abi         conda-forge/linux-64::python_abi-3.9-2_cp39 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  _libgcc_mutex                                   pkgs/main --> conda-forge \n",
      "  certifi            pkgs/main/linux-64::certifi-2023.11.1~ --> conda-forge/noarch::certifi-2023.11.17-pyhd8ed1ab_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: | By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
      "\n",
      "done\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting pandas==1.3.5\n",
      "  Using cached pandas-1.3.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "Collecting pyyaml\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: pyarrow in /home/anton/.local/lib/python3.9/site-packages (11.0.0)\n",
      "Collecting numba==0.57.1\n",
      "  Using cached numba-0.57.1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting scikit-learn==1.0.2\n",
      "  Using cached scikit_learn-1.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.4 MB)\n",
      "Requirement already satisfied: numpy in ./pytorch-env/lib/python3.9/site-packages (1.26.3)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.11.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting fair-esm\n",
      "  Using cached fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
      "Collecting python-dateutil>=2.7.3 (from pandas==1.3.5)\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting pytz>=2017.3 (from pandas==1.3.5)\n",
      "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting llvmlite<0.41,>=0.40.0dev0 (from numba==0.57.1)\n",
      "  Using cached llvmlite-0.40.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.24.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn==1.0.2)\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7.3->pandas==1.3.5)\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached numba-0.57.1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
      "Using cached numpy-1.24.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Using cached scipy-1.11.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.6 MB)\n",
      "Using cached llvmlite-0.40.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)\n",
      "Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: pytz, fair-esm, tqdm, threadpoolctl, six, pyyaml, numpy, llvmlite, joblib, scipy, python-dateutil, numba, scikit-learn, pandas\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.3\n",
      "    Uninstalling numpy-1.26.3:\n",
      "      Successfully uninstalled numpy-1.26.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dask 2023.3.1 requires click>=7.0, which is not installed.\n",
      "dask 2023.3.1 requires cloudpickle>=1.1.1, which is not installed.\n",
      "dask 2023.3.1 requires fsspec>=0.6.0, which is not installed.\n",
      "dask 2023.3.1 requires packaging>=20.0, which is not installed.\n",
      "dask 2023.3.1 requires partd>=1.2.0, which is not installed.\n",
      "dask 2023.3.1 requires toolz>=0.8.2, which is not installed.\n",
      "distributed 2023.3.1 requires click>=8.0, which is not installed.\n",
      "distributed 2023.3.1 requires cloudpickle>=1.5.0, which is not installed.\n",
      "distributed 2023.3.1 requires locket>=1.0.0, which is not installed.\n",
      "distributed 2023.3.1 requires msgpack>=1.0.0, which is not installed.\n",
      "distributed 2023.3.1 requires packaging>=20.0, which is not installed.\n",
      "distributed 2023.3.1 requires psutil>=5.7.0, which is not installed.\n",
      "distributed 2023.3.1 requires sortedcontainers>=2.0.5, which is not installed.\n",
      "distributed 2023.3.1 requires tblib>=1.6.0, which is not installed.\n",
      "distributed 2023.3.1 requires toolz>=0.10.0, which is not installed.\n",
      "distributed 2023.3.1 requires tornado>=6.0.3, which is not installed.\n",
      "distributed 2023.3.1 requires zict>=2.1.0, which is not installed.\n",
      "fastparquet 2023.2.0 requires fsspec, which is not installed.\n",
      "fastparquet 2023.2.0 requires packaging, which is not installed.\n",
      "gdown 4.6.4 requires beautifulsoup4, which is not installed.\n",
      "statsmodels 0.13.5 requires packaging>=21.3, which is not installed.\n",
      "fastparquet 2023.2.0 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fair-esm-2.0.0 joblib-1.3.2 llvmlite-0.40.1 numba-0.57.1 numpy-1.24.4 pandas-1.3.5 python-dateutil-2.8.2 pytz-2023.3.post1 pyyaml-6.0.1 scikit-learn-1.0.2 scipy-1.11.4 six-1.16.0 threadpoolctl-3.2.0 tqdm-4.66.1\n",
      "Collecting obonet\n",
      "  Using cached obonet-1.0.0-py3-none-any.whl (9.2 kB)\n",
      "Collecting pyvis\n",
      "  Using cached pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "Collecting torchmetrics\n",
      "  Using cached torchmetrics-1.3.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting torchsummary\n",
      "  Using cached torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.99-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting psutil\n",
      "  Using cached psutil-5.9.7-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: networkx in ./pytorch-env/lib/python3.9/site-packages (from obonet) (3.1)\n",
      "Collecting ipython>=5.3.0 (from pyvis)\n",
      "  Using cached ipython-8.18.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in ./pytorch-env/lib/python3.9/site-packages (from pyvis) (3.1.2)\n",
      "Collecting jsonpickle>=1.4.1 (from pyvis)\n",
      "  Using cached jsonpickle-3.0.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: filelock in ./pytorch-env/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Using cached huggingface_hub-0.20.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./pytorch-env/lib/python3.9/site-packages (from transformers) (1.24.4)\n",
      "Collecting packaging>=20.0 (from transformers)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./pytorch-env/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2023.12.25-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in ./pytorch-env/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Using cached tokenizers-0.15.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Using cached safetensors-0.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./pytorch-env/lib/python3.9/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./pytorch-env/lib/python3.9/site-packages (from torchmetrics) (2.0.1)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Using cached lightning_utilities-0.10.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers)\n",
      "  Using cached fsspec-2023.12.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./pytorch-env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Collecting decorator (from ipython>=5.3.0->pyvis)\n",
      "  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis)\n",
      "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting matplotlib-inline (from ipython>=5.3.0->pyvis)\n",
      "  Using cached matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
      "Collecting prompt-toolkit<3.1.0,>=3.0.41 (from ipython>=5.3.0->pyvis)\n",
      "  Using cached prompt_toolkit-3.0.43-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pygments>=2.4.0 (from ipython>=5.3.0->pyvis)\n",
      "  Using cached pygments-2.17.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting stack-data (from ipython>=5.3.0->pyvis)\n",
      "  Using cached stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting traitlets>=5 (from ipython>=5.3.0->pyvis)\n",
      "  Using cached traitlets-5.14.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting exceptiongroup (from ipython>=5.3.0->pyvis)\n",
      "  Using cached exceptiongroup-1.2.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting pexpect>4.3 (from ipython>=5.3.0->pyvis)\n",
      "  Using cached pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./pytorch-env/lib/python3.9/site-packages (from jinja2>=2.9.6->pyvis) (2.1.3)\n",
      "Requirement already satisfied: setuptools in ./pytorch-env/lib/python3.9/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (68.2.2)\n",
      "Requirement already satisfied: sympy in ./pytorch-env/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./pytorch-env/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./pytorch-env/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./pytorch-env/lib/python3.9/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./pytorch-env/lib/python3.9/site-packages (from requests->transformers) (2023.11.17)\n",
      "Collecting parso<0.9.0,>=0.8.3 (from jedi>=0.16->ipython>=5.3.0->pyvis)\n",
      "  Using cached parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
      "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=5.3.0->pyvis)\n",
      "  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting wcwidth (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis)\n",
      "  Using cached wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting executing>=1.2.0 (from stack-data->ipython>=5.3.0->pyvis)\n",
      "  Using cached executing-2.0.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting asttokens>=2.1.0 (from stack-data->ipython>=5.3.0->pyvis)\n",
      "  Using cached asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pure-eval (from stack-data->ipython>=5.3.0->pyvis)\n",
      "  Using cached pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./pytorch-env/lib/python3.9/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./pytorch-env/lib/python3.9/site-packages (from asttokens>=2.1.0->stack-data->ipython>=5.3.0->pyvis) (1.16.0)\n",
      "Using cached transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "Using cached torchmetrics-1.3.0-py3-none-any.whl (840 kB)\n",
      "Using cached psutil-5.9.7-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (285 kB)\n",
      "Using cached huggingface_hub-0.20.2-py3-none-any.whl (330 kB)\n",
      "Using cached ipython-8.18.1-py3-none-any.whl (808 kB)\n",
      "Using cached jsonpickle-3.0.2-py3-none-any.whl (40 kB)\n",
      "Using cached lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached regex-2023.12.25-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "Using cached safetensors-0.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached tokenizers-0.15.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "Using cached fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
      "Using cached pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "Using cached prompt_toolkit-3.0.43-py3-none-any.whl (386 kB)\n",
      "Using cached pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
      "Using cached traitlets-5.14.1-py3-none-any.whl (85 kB)\n",
      "Using cached exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "Using cached asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
      "Using cached executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
      "Using cached wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Installing collected packages: wcwidth, torchsummary, sentencepiece, pure-eval, ptyprocess, traitlets, safetensors, regex, pygments, psutil, prompt-toolkit, pexpect, parso, packaging, obonet, jsonpickle, fsspec, executing, exceptiongroup, decorator, asttokens, stack-data, matplotlib-inline, lightning-utilities, jedi, huggingface-hub, torchmetrics, tokenizers, ipython, transformers, pyvis\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dask 2023.3.1 requires click>=7.0, which is not installed.\n",
      "dask 2023.3.1 requires cloudpickle>=1.1.1, which is not installed.\n",
      "dask 2023.3.1 requires partd>=1.2.0, which is not installed.\n",
      "dask 2023.3.1 requires toolz>=0.8.2, which is not installed.\n",
      "distributed 2023.3.1 requires click>=8.0, which is not installed.\n",
      "distributed 2023.3.1 requires cloudpickle>=1.5.0, which is not installed.\n",
      "distributed 2023.3.1 requires locket>=1.0.0, which is not installed.\n",
      "distributed 2023.3.1 requires msgpack>=1.0.0, which is not installed.\n",
      "distributed 2023.3.1 requires sortedcontainers>=2.0.5, which is not installed.\n",
      "distributed 2023.3.1 requires tblib>=1.6.0, which is not installed.\n",
      "distributed 2023.3.1 requires toolz>=0.10.0, which is not installed.\n",
      "distributed 2023.3.1 requires tornado>=6.0.3, which is not installed.\n",
      "distributed 2023.3.1 requires zict>=2.1.0, which is not installed.\n",
      "fastparquet 2023.2.0 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed asttokens-2.4.1 decorator-5.1.1 exceptiongroup-1.2.0 executing-2.0.1 fsspec-2023.12.2 huggingface-hub-0.20.2 ipython-8.18.1 jedi-0.19.1 jsonpickle-3.0.2 lightning-utilities-0.10.0 matplotlib-inline-0.1.6 obonet-1.0.0 packaging-23.2 parso-0.8.3 pexpect-4.9.0 prompt-toolkit-3.0.43 psutil-5.9.7 ptyprocess-0.7.0 pure-eval-0.2.2 pygments-2.17.2 pyvis-0.3.2 regex-2023.12.25 safetensors-0.4.1 sentencepiece-0.1.99 stack-data-0.6.3 tokenizers-0.15.0 torchmetrics-1.3.0 torchsummary-1.5.1 traitlets-5.14.1 transformers-4.36.2 wcwidth-0.2.13\n"
     ]
    }
   ],
   "source": [
    "!./create-rapids-env.sh {BASE_PATH}\n",
    "!./create-pytorch-env.sh {BASE_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Get the input data\n",
    "\n",
    "Here we describe what should be stored in the working dir to reproduce the results\n",
    "\n",
    "Following data scheme was provided by Kaggle:\n",
    "\n",
    "    ./Train - cafa train data\n",
    "    ./Test (targets) - cafa test data\n",
    "    ./sample_submission.tsv - cafa ssub\n",
    "    ./IA.txt - cafa IA\n",
    "\n",
    "    \n",
    "Following are the solution code libraries, scipts, and notebooks used for training:\n",
    "\n",
    "    ./protlib\n",
    "    ./protnn\n",
    "    ./nn_solution\n",
    "    \n",
    "And the installed envs\n",
    "\n",
    "    ./pytorch-env\n",
    "    ./rapids-env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Produce the helpers data\n",
    "\n",
    "First, we made some preprocessing of the input data to store everything in format that is convinient to us to handle and manipulate. Here is the structure:\n",
    "\n",
    "    ./helpers\n",
    "        ./fasta - fasta files stored as feather\n",
    "            ./train_seq.feather\n",
    "            ./test_seq.feather\n",
    "        ./real_targets - targets stored as n_proteins x n_terms parquet containing 0/1/NaN values\n",
    "            ./biological_process\n",
    "                ./part_0.parquet\n",
    "                ...\n",
    "                ./part_14.parquet\n",
    "                ./nulls.pkl - NaN rate of each term\n",
    "                ./priors.pkl - prior mean of each term (excluding NaN cells, like np.nanmean)\n",
    "            ./cellular_component\n",
    "            ./molecular_function\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1524980it [00:02, 750164.78it/s]\n",
      "1339949it [00:00, 1637363.93it/s]\n",
      "/home/anton/CAFA5-protein-function-prediction-2nd-place\n",
      "15it [21:02, 84.19s/it]\n",
      "CPU times: user 11.5 s, sys: 4.42 s, total: 15.9 s\n",
      "Wall time: 23min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# parse fasta files and save as feather\n",
    "!{RAPIDS_ENV} protlib/scripts/parse_fasta.py \\\n",
    "    --config-path {CONFIG_PATH}\n",
    "\n",
    "# convert targets to parquet and calculate priors\n",
    "!{RAPIDS_ENV} protlib/scripts/create_helpers.py \\\n",
    "    --config-path {CONFIG_PATH} \\\n",
    "    --batch-size 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Get external data\n",
    "\n",
    "Datasets downloaded from outside and then processed. First step is downloading and parsing the datasets. After parsing, script will separate the datasets by the evidence codes. The most important split for us is kaggle/no-kaggle split. We refer `kaggle` as experimental codes, `no-kaggle` as electornic labeling, that will be used as features for the stacker models. Downloading takes quite a long time, while processing takes about 1 hour. The required structure after execution\n",
    "\n",
    "    ./temporal - extra data downloaded from http://ftp.ebi.ac.uk/pub/databases/GO/goa/old/UNIPROT/\n",
    "    ./labels   - extracted and propagated labeling\n",
    "        ./prop_test_leak_no_dup.tsv - leakage labeling\n",
    "        ./prop_test_no_kaggle.tsv   - electronic labels test\n",
    "        ./prop_train_no_kaggle.tsv  - electronic labels train\n",
    "        \n",
    "    ./cafa-terms-diff.tsv - reproduced difference between ML's dataset and our parsed labels\n",
    "    ./prop_quickgo51.tsv  - reproduced MT's quickgo 37 proteins\n",
    "    \n",
    "    \n",
    "Other files are temporary and not needed for future work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download external data from ebi.ac.uk\n",
    "!{RAPIDS_ENV} protlib/scripts/downloads/dw_goant.py \\\n",
    "    --config-path {CONFIG_PATH}\n",
    "\n",
    "# # parse the files\n",
    "!{RAPIDS_ENV} protlib/scripts/parse_go_single.py \\\n",
    "    --file goa_uniprot_all.gaf.216.gz \\\n",
    "    --config-path {CONFIG_PATH}\n",
    "\n",
    "!{RAPIDS_ENV} protlib/scripts/parse_go_single.py \\\n",
    "    --file goa_uniprot_all.gaf.214.gz \\\n",
    "    --config-path {CONFIG_PATH} \\\n",
    "    --output old214"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is propagation. Since ebi.ac datasets contains the labeling without propagation, we will apply the rules provided in organizer's repo to labeling more terms. We will do it only for `goa_uniprot_all.gaf.216.gz` datasets since it is the actual dataset at the active competition phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = BASE_PATH + '/temporal'\n",
    "\n",
    "for file in glob.glob(folder + '/labels/train*') + glob.glob(folder + '/labels/test*'):\n",
    "    name = folder + '/labels/prop_' + file.split('/')[-1]\n",
    "\n",
    "    !{RAPIDS_ENV} {BASE_PATH}/protlib/scripts/prop_tsv.py \\\n",
    "        --path {file} \\\n",
    "        --graph {BASE_PATH}/Train/go-basic.obo \\\n",
    "        --output {name} \\\n",
    "        --device 0 \\\n",
    "        --batch_size 30000 \\\n",
    "        --batch_inner 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last part is reproducing MT's datasets that are commonly used in all public kernels. We didn't use it directly, but we used `cafa-terms-diff` dataset, that represents the difference between our labeling obtained by parsing `goa_uniprot_all.gaf.216.gz` dataset and `all_dict.pkl` dataset given by MT. As he claims in the dicussion [here](https://www.kaggle.com/competitions/cafa-5-protein-function-prediction/discussion/404853#2329935) he used the same FTP source as we. But our source is more actual than the public. So the difference is actually the temporal. After analysis, we find out, that we are able to reproduce it as the difference between `goa_uniprot_all.gaf.216.gz` and `goa_uniprot_all.gaf.214.gz` sources. So, we just create `cafa-terms-diff` dataset by the given script. The only difference between the source in the kaggle script and used here is deduplication. We removed duplicated protein/terms pairs from the dataset, it has almost zero impact on the metric value (less than 1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets\n",
    "!{RAPIDS_ENV} {BASE_PATH}/protlib/scripts/reproduce_mt.py \\\n",
    "    --path {BASE_PATH}/temporal \\\n",
    "    --graph {BASE_PATH}/Train/go-basic.obo\n",
    "\n",
    "# # make propagation for quickgo51.tsv\n",
    "!{RAPIDS_ENV} {BASE_PATH}/protlib/scripts/prop_tsv.py \\\n",
    "    --path {BASE_PATH}/temporal/quickgo51.tsv \\\n",
    "    --graph {BASE_PATH}/Train/go-basic.obo \\\n",
    "    --output {BASE_PATH}/temporal/prop_quickgo51.tsv \\\n",
    "    --device 0 \\\n",
    "    --batch_size 30000 \\\n",
    "    --batch_inner 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Preparation step for neural networks\n",
    "\n",
    "Produce some helpers to train NN model. Creates the following data:\n",
    "\n",
    "    ./helpers/feats\n",
    "        ./train_ids_cut43k.npy\n",
    "        ./Y_31466_labels.npy\n",
    "        ./Y_31466_sparse_float32.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5363863, 3)\n",
      "GO:0005575    92912\n",
      "GO:0008150    92210\n",
      "GO:0110165    91286\n",
      "GO:0003674    78637\n",
      "GO:0005622    70785\n",
      "              ...  \n",
      "GO:0031772        1\n",
      "GO:0042324        1\n",
      "GO:0031771        1\n",
      "GO:0051041        1\n",
      "GO:0102628        1\n",
      "Name: term, Length: 31466, dtype: int64\n",
      "aspect\n",
      "BPO    21285\n",
      "CCO     2957\n",
      "MFO     7224\n",
      "Name: term, dtype: int64\n",
      "CPU times: user 104 ms, sys: 28.1 ms, total: 132 ms\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!{PYTORCH_ENV} {BASE_PATH}/nn_solution/prepare.py \\\n",
    "    --config-path {CONFIG_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘embeds’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 T5 pretrained inference\n",
    "\n",
    "    ./embeds\n",
    "        ./t5\n",
    "            ./train_ids.npy\n",
    "            ./train_embeds.npy\n",
    "            ./test_ids.npy\n",
    "            ./test_embeds.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!{PYTORCH_ENV} {BASE_PATH}/nn_solution/t5.py \\\n",
    "    --config-path {CONFIG_PATH} \\\n",
    "    --device 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ESM pretrained inference\n",
    "\n",
    "    ./embeds\n",
    "        ./esm_small\n",
    "            ./train_ids.npy\n",
    "            ./train_embeds.npy\n",
    "            ./test_ids.npy\n",
    "            ./test_embeds.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!{PYTORCH_ENV} {BASE_PATH}/nn_solution/esm2sm.py \\\n",
    "    --config-path {CONFIG_PATH} \\\n",
    "    --device 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘models’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train and inference py-boost models\n",
    "\n",
    "GBDT models description:\n",
    "\n",
    "1) Features: T5 + taxon, targets: multilabel\n",
    "\n",
    "2) Features: T5 + taxon, targets: conditional\n",
    "\n",
    "3) Features: T5 + ESM + taxon, targets: multilabel\n",
    "\n",
    "4) Features: T5 + ESM + taxon, targets: conditional\n",
    "\n",
    "Pipeline and hyperparameters are the same for all the models. Target is 4500 output: BP 3000, MF: 1000, CC: 500. All models could be ran in parallel to save a time. We used single V100 32GB and it requires about 15 hours to train 5 fold CV loop for each model type. 32GB GPU RAM is required, otherwise OOM will occur. Structure is:\n",
    "    \n",
    "    ./models\n",
    "        ./pb_t54500_raw\n",
    "            ./models_0.pkl\n",
    "            ...\n",
    "            ./models_4.pkl\n",
    "            ./oof_pred.pkl\n",
    "            ./test_pred.pkl\n",
    "        ./pb_t54500_cond\n",
    "            ...\n",
    "        ./pb_t5esm4500_raw\n",
    "            ...\n",
    "        ./pb_t5esm4500_cond\n",
    "            ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pb_t54500_raw\n",
      "True\n",
      "trg filled\n",
      "trg filled\n",
      "trg filled\n",
      "(142246, 1056) (141865, 1056)\n",
      "(113769,) (28477,)\n",
      "[23:01:58] Stdout logging level is INFO.\n",
      "[23:01:58] GDBT train starts. Max iter 20000, early stopping rounds 300\n",
      "[23:02:26] Iter 0; Sample 0, BCE = 0.03245292768610193; \n",
      "[23:03:09] Iter 100; Sample 0, BCE = 0.02795873129372635; \n",
      "Training pb_t54500_cond\n",
      "Training pb_t5esm4500_raw\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'child' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpexpect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Vanilla Pexpect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mflush\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command, args, timeout, maxread, searchwindowsize, logfile, cwd, env, ignore_sighup, echo, preexec_fn, encoding, codec_errors, dimensions, use_poll)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreexec_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_poll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_poll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawn\u001b[0;34m(self, command, args, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mcommand_with_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcommand_with_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/utils.py\u001b[0m in \u001b[0;36mwhich\u001b[0;34m(filename, env)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Special case where filename contains an explicit path.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_executable_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/utils.py\u001b[0m in \u001b[0;36mis_executable_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# follow symlinks,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mfpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/posixpath.py\u001b[0m in \u001b[0;36mrealpath\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_joinrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/posixpath.py\u001b[0m in \u001b[0;36m_joinrealpath\u001b[0;34m(path, rest, seen)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mseen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnewpath\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;31m# not resolved symlink\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_joinrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/posixpath.py\u001b[0m in \u001b[0;36m_joinrealpath\u001b[0;34m(path, rest, seen)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcurdir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0;31m# current dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cfba7678fa34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training {model_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{RAPIDS_ENV} {BASE_PATH}/protlib/scripts/train_pb.py          --config-path {CONFIG_PATH}          --model-name {model_name}          --device 0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m   2451\u001b[0m         \u001b[0;31m# a non-None value would trigger :func:`sys.displayhook` calls.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m         \u001b[0;31m# Instead, we store the exit_code in user_ns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2453\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msystem_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m# (the character is known as ETX for 'End of Text', see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;31m# curses.ascii.ETX).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0;31m# Read and print any more output the program might produce on its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;31m# way out.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'child' referenced before assignment"
     ]
    }
   ],
   "source": [
    "for model_name in ['pb_t54500_raw', 'pb_t54500_cond', 'pb_t5esm4500_raw', 'pb_t5esm4500_cond', ]:\n",
    "\n",
    "    print(f'Training {model_name}')\n",
    "\n",
    "    !{RAPIDS_ENV} {BASE_PATH}/protlib/scripts/train_pb.py \\\n",
    "        --config-path {CONFIG_PATH} \\\n",
    "        --model-name {model_name} \\\n",
    "        --device 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Train and inference logreg models\n",
    "\n",
    "Logistic Regression models description:\n",
    "\n",
    "1) Features: T5 + taxon, targets: multilabel\n",
    "\n",
    "2) Features: T5 + taxon, targets: conditional\n",
    "\n",
    "\n",
    "Pipeline and hyperparameters are the same for all the models. Target is 13500 output: BP 10000, MF: 2000, CC: 1500. All models could be ran in parallel to save a time. We used single V100 32GB and it requires about 10 hours for model 1 and 2 hours for model 2 to train 5 fold CV loop. 32GB GPU RAM is required, otherwise OOM will occur. Structure is:\n",
    "\n",
    "    ./helpers\n",
    "        ./folds_gkf.npy\n",
    "    ./models\n",
    "        ./lin_t5_raw\n",
    "            ./models_0.pkl\n",
    "            ...\n",
    "            ./models_4.pkl\n",
    "            ./oof_pred.pkl\n",
    "            ./test_pred.pkl\n",
    "        ./lin_t5_cond\n",
    "            ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in ['lin_t5_raw', 'lin_t54500_cond']:\n",
    "\n",
    "    print(f'Training {model_name}')\n",
    "\n",
    "    !{RAPIDS_ENV} {BASE_PATH}/protlib/scripts/train_lin.py \\\n",
    "        --config-path {CONFIG_PATH} \\\n",
    "        --model-name {model_name} \\\n",
    "        --device 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Train and inference NN models\n",
    "\n",
    "Structure is:\n",
    "\n",
    "    ./models\n",
    "        ./nn_serg\n",
    "            ./model_0_0.pt\n",
    "            ...\n",
    "            ./model_11_4.pt\n",
    "            ./pytorch-keras-etc-3-blend-cafa-metric-etc.pkl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create train folds (the same as used for pb_t54500_cond model)\n",
    "!{RAPIDS_ENV} {BASE_PATH}/protlib/scripts/create_gkf.py \\\n",
    "    --config-path {CONFIG_PATH}\n",
    "\n",
    "# train models\n",
    "!{PYTORCH_ENV} {BASE_PATH}/nn_solution/train_models.py \\\n",
    "    --config-path {CONFIG_PATH} \\\n",
    "    --device 0\n",
    "\n",
    "# inference models\n",
    "!{PYTORCH_ENV} {BASE_PATH}/nn_solution/inference_models.py \\\n",
    "    --config-path {CONFIG_PATH} \\\n",
    "    --device 0\n",
    "\n",
    "# reformat to use in stack\n",
    "!{PYTORCH_ENV} {BASE_PATH}/nn_solution/make_pkl.py \\\n",
    "    --config-path {CONFIG_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Final model\n",
    "\n",
    "### 4.1. Train GCN models\n",
    "\n",
    "This step is training 3 independent stacking models for each ontology. Models are trained on single V100 GPU and it takes about 13 hours for BP, 4 hours for MF and 2 hours for CC. 32 GB GPU RAM is required to fit. Could be trained in parallel if 2 GPUs are avaliable - BP and MF/CC. Structure:\n",
    "\n",
    "    ./models\n",
    "        ./gcn\n",
    "            ./bp\n",
    "                ./checkpoint.pth\n",
    "            ./mf\n",
    "                ./checkpoint.pth\n",
    "            ./cc\n",
    "                ./checkpoint.pth\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for ont in ['bp', 'mf', 'cc']:\n",
    "    !{PYTORCH_ENV} {BASE_PATH}/protnn/scripts/train_gcn.py \\\n",
    "        --config-path {CONFIG_PATH} \\\n",
    "        --ontology {ont} \\\n",
    "        --device 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Inference GCN models and TTA\n",
    "\n",
    "Inference and Test-Time-Augmentation. Structure:\n",
    "\n",
    "    ./models\n",
    "        ./gcn\n",
    "            ./pred_tta_0.tsv\n",
    "            ...\n",
    "            ./pred_tta_3.tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "!{PYTORCH_ENV} {BASE_PATH}/protnn/scripts/predict_gcn.py \\\n",
    "    --config-path {CONFIG_PATH} \\\n",
    "    --device 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Postprocessing and build submission file\n",
    "\n",
    "Here we do the following:\n",
    "\n",
    "1) Average TTA predictions\n",
    "2) Perform min prop\n",
    "3) Perform max prop\n",
    "4) Average min/max prop steps, add external leakage data and make submission\n",
    "\n",
    "Structure:\n",
    "\n",
    "    ./models\n",
    "        ./postproc\n",
    "            ./pred.tsv     - avg TTA\n",
    "            ./pred_min.tsv - min prop\n",
    "            ./pred_max.tsv - max prop\n",
    "            \n",
    "    ./sub\n",
    "        ./submission.tsv   - final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we have 4 TTA predictions, we need to aggregate all as an average\n",
    "!{RAPIDS_ENV} {BASE_PATH}/protlib/scripts/postproc/collect_ttas.py \\\n",
    "    --config-path {CONFIG_PATH} \\\n",
    "    --device 0\n",
    "\n",
    "# create 0.3 * pred + 0.7 * max children propagation\n",
    "!{RAPIDS_ENV} {BASE_PATH}/protlib/scripts/postproc/step.py \\\n",
    "    --config-path {CONFIG_PATH} \\\n",
    "    --device 0 \\\n",
    "    --batch_size 30000 \\\n",
    "    --batch_inner 3000 \\\n",
    "    --lr 0.7 \\\n",
    "    --direction min\n",
    "\n",
    "# create 0.3 * pred + 0.7 * min parents propagation\n",
    "!{RAPIDS_ENV} {BASE_PATH}/protlib/scripts/postproc/step.py \\\n",
    "    --config-path {CONFIG_PATH} \\\n",
    "    --device 0 \\\n",
    "    --batch_size 30000 \\\n",
    "    --batch_inner 3000 \\\n",
    "    --lr 0.7 \\\n",
    "    --direction max\n",
    "\n",
    "# here we average min prop and max prop solutions, mix with cafa-terms-diff and quickgo51 datasets from 1.4\n",
    "!{RAPIDS_ENV} {BASE_PATH}/protlib/scripts/postproc/make_submission.py \\\n",
    "    --config-path {CONFIG_PATH} \\\n",
    "    --device 0 \\\n",
    "    --max-rate 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "\n",
    "Result is stored in `./sub/submission.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head {BASE_PATH}/sub/submission.tsv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
